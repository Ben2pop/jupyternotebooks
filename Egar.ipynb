{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import threading\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import pandas\n",
    "import collections\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from datetime import datetime\n",
    "import html as h\n",
    "\n",
    "class SCRAPER:\n",
    "\n",
    "\tURL = \"https://www.sec.gov/cgi-bin/browse-edgar?CIK=%s&start=%d&count=100\"\n",
    "\tLOCK = threading.Semaphore( value=1 )\n",
    "\tTHREADS = 0\n",
    "\tCCOUNT = 0\n",
    "\tERRORS = 0\n",
    "\tFILECOUNT = 0\n",
    "\tFILES = True\n",
    "\tLINKS = []\n",
    "\tLOOPER = []\n",
    "\tDATA = {}\n",
    "\tHEADERS = {\n",
    "\t\t'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:64.0) Gecko/20100101 Firefox/64.0',\n",
    "\t}\n",
    "\n",
    "\tdef __init__(self, _ticker, _howmany, _threads=5, _verbose=False):\n",
    "\t\t''' A simple and straightforward Scraper! '''\n",
    "\t\tself.ticker = _ticker\n",
    "\t\tself.count  = _howmany\n",
    "\t\tself.max    = _threads   ## More threads more speed except for the file accumulation process  ##\n",
    "\t\tself.verbose = _verbose  ## Verbose Mode. Print Messages!  ##\n",
    "\n",
    "\tdef table(self, _html):\n",
    "\t\tlinks, html = [], soup( _html, features=\"lxml\" )\n",
    "\t\ttable = html.find( \"table\", attrs={ 'class': 'tableFile2' } )\n",
    "\n",
    "\t\t## Extracting Data from tables ##\n",
    "\t\tif table:\n",
    "\t\t\trows = table.findChildren( \"tr\" )[1:]\n",
    "\t\t\tfor row in rows:\n",
    "\t\t\t\t( file, format, desc, date, number ) = row.findChildren( \"td\" )\n",
    "\t\t\t\tif file.text == \"10-Q\" or file.text == \"10-q\" or file.text == \"10q\" or file.text == \"10Q\":\n",
    "\t\t\t\t\tintdata = format.findChild( \"a\", attrs={ 'id': 'interactiveDataBtn' } )\n",
    "\t\t\t\t\tif intdata:\n",
    "\t\t\t\t\t\tlinks.append( (date.text, \"https://www.sec.gov%s\" % intdata.get( \"href\" )) )\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tif self.verbose:\n",
    "\t\t\t\t\t\t\tprint(\"[!] Received 10Q file without interactive data link. \")\n",
    "\t\t\treturn links\n",
    "\t\telse:\n",
    "\t\t\tself.FILES = False ## Stop if no table is detected ##\n",
    "\n",
    "\tdef request(self):\n",
    "\t\turl = self.URL % ( self.ticker, self.CCOUNT )\n",
    "\t\tfor n in range( 3 ):                             ##  Retry three times in case an error occurs  ##\n",
    "\t\t\ttry:\n",
    "\t\t\t\tr = requests.get( url, headers=self.HEADERS )\n",
    "\t\t\t\tif r.status_code == 200:\n",
    "\t\t\t\t\tself.CCOUNT += 100\n",
    "\t\t\t\t\tq10links = self.table( r.text )\n",
    "\t\t\t\t\tself.LINKS += q10links\n",
    "\t\t\t\t\tif self.verbose:\n",
    "\t\t\t\t\t\tprint(\"[*] Received Number of Files: %d Requested Counter: %d\" % (len( q10links ), self.CCOUNT))\n",
    "\t\t\t\t\tself.FILECOUNT += len( q10links )\n",
    "\t\t\t\t\tif self.FILECOUNT >= self.count:\n",
    "\t\t\t\t\t\tself.FILES = False\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\traise Exception( \"[~] Invalid Response Code Received : %d\" % r.status_code )\n",
    "\t\t\t\tbreak\n",
    "\t\t\texcept KeyboardInterrupt:\n",
    "\t\t\t\traise KeyboardInterrupt()\n",
    "\t\t\texcept:\n",
    "\t\t\t\tif self.verbose:\n",
    "\t\t\t\t\tprint(\"[!] Failed connection to Server. Check Your Connection. Trying Again!\")\n",
    "\n",
    "\tdef search(self):\n",
    "\t\tif self.verbose:\n",
    "\t\t\tprint(\"[^] Requesting 10Q files from the Server!\")\n",
    "\t\twhile self.FILES:\n",
    "\t\t\tself.request(  )\n",
    "\t\tif self.verbose:\n",
    "\t\t\tprint(\"[*] Acquired Number of 10Q files: %d\" % ( self.count ))\n",
    "\n",
    "\tdef pprequest( self, _link, _type ):\n",
    "\t\t''' The main function to extract all financial statements data. It accepts the link to financial document and return it's dataframe as of created by pandas\n",
    "\t\t\tDataFrame() object. It is highly flexbile and determines whether there are any colspans in the table or not. If there are, they will be extracted and\n",
    "\t\t\taccording deleted when the next colspan is encoundered. whether the argument _link is the link to the financial document and _type is the document type.\n",
    "\t\t\t_type argument is only for testing purposes. '''\n",
    "\t\ttry:\n",
    "\t\t\tr = requests.get( _link, headers=self.HEADERS )\n",
    "\t\texcept:\n",
    "\t\t\tif self.verbose:\n",
    "\t\t\t\tprint(\"[!] Error Requesting Financial Statement. Type: %s\" % _type)\n",
    "\t\t\treturn pandas.DataFrame()\n",
    "\t\tif r.status_code == 200:\n",
    "\t\t\thtml = soup( r.text, features=\"lxml\" )\n",
    "\t\t\ttable = html.find( \"table\", attrs={ 'class': 'report' } )\n",
    "\t\t\tif table:\n",
    "\t\t\t\trows, differ, data = table.findChildren( \"tr\" ), 0, collections.OrderedDict()\n",
    "\t\t\t\tfor row in rows:\n",
    "\t\t\t\t\tif row.findChild( \"th\" ):\n",
    "\t\t\t\t\t\tdiffer += 1\n",
    "\t\t\t\theaderslist = rows[ :differ ]\n",
    "\t\t\t\ttabdatalist = rows[ differ: ]\n",
    "\t\t\t\tfor headers in headerslist:\n",
    "\t\t\t\t\theaderslist[ headerslist.index( headers ) ] = headers.findChildren( \"th\" )\n",
    "\t\t\t\tfor tabdata in tabdatalist:\n",
    "\t\t\t\t\ttabdatalist[ tabdatalist.index( tabdata ) ] = tabdata.findChildren( \"td\" )\n",
    "\t\t\t\tfor headers in headerslist:\n",
    "\t\t\t\t\tfor header in headers:\n",
    "\t\t\t\t\t\tif header.get( \"colspan\" ) and int(header.get( \"colspan\" )) > 1:\n",
    "\t\t\t\t\t\t\tcolspan = int( header.get( \"colspan\" ) )\n",
    "\t\t\t\t\t\t\tfor col in range( colspan ):\n",
    "\t\t\t\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\t\t\t\tdata[ h.unescape( header.text ) + \" - \" + h.unescape( headerslist[ headerslist.index( headers ) + 1 ][ col ].text ).strip( \"\\n\" ) ] = []\n",
    "\t\t\t\t\t\t\t\texcept IndexError:\n",
    "\t\t\t\t\t\t\t\t\tdata[ h.unescape( header.text ).strip( \"\\n\" ) ] = []\n",
    "\t\t\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\t\t\tdel headerslist[ headerslist.index( headers ) + 1 ][ :colspan ]\n",
    "\t\t\t\t\t\t\texcept:\n",
    "\t\t\t\t\t\t\t\tpass\n",
    "\t\t\t\t\t\t\tdel colspan\n",
    "\t\t\t\t\t\telse: \n",
    "\t\t\t\t\t\t\tdata[ h.unescape( header.text ) ] = []\n",
    "\t\t\t\tindexer = list(data.items())\n",
    "\t\t\t\tfor ( _key, _value ) in indexer:\n",
    "\t\t\t\t\tfor tabdata in tabdatalist:\n",
    "\t\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\t\t\tdata[ _key ].append( int(float(h.unescape( tabdata[ indexer.index( ( _key, _value ) ) ].text ).strip( \"\\n\" ).replace(\" \", \"\").replace(\"$\", \"\").replace(\",\", \"\").replace(\"(\", \"\").replace(\")\", \"\"))) )\n",
    "\t\t\t\t\t\t\texcept ValueError:\n",
    "\t\t\t\t\t\t\t\tdata[ _key ].append( h.unescape( tabdata[ indexer.index( ( _key, _value ) ) ].text ).strip( \"\\n\" ) )\n",
    "\t\t\t\t\t\texcept IndexError:\n",
    "\t\t\t\t\t\t\tdata[ _key ].append( \"\" )\n",
    "\t\t\t\tpd = pandas.DataFrame( data, index=range( len( tabdatalist ) ) )\n",
    "\t\t\t\tpd = pd.set_index( list( pd )[0] )\n",
    "\t\t\t\treturn pd\n",
    "\t\t\telse:\t\n",
    "\t\t\t\treturn pandas.DataFrame()\n",
    "\n",
    "\tdef prequest( self, _date, _link ):\n",
    "\t\tself.THREADS += 1\n",
    "\n",
    "\t\tif self.verbose:\n",
    "\t\t\tself.LOCK.acquire()\n",
    "\t\t\tprint(\"[^] Requesting Q10 File! Date: %s\" % (_date))\n",
    "\t\t\tself.LOCK.release()\n",
    "\n",
    "\t\tfor n in range(2):\n",
    "\t\t\tr = requests.get( _link )\n",
    "\t\t\tif r.status_code == 200:\n",
    "\t\t\t\thtml = soup( r.text, features=\"lxml\" )\n",
    "\t\t\t\tr1link  = re.search( r\"reports\\[0\\+1\\] = \\\"(.*?)\\\";\", r.text )\n",
    "\t\t\t\tr2link  = re.search( r\"reports\\[1\\+1\\] = \\\"(.*?)\\\";\", r.text )\n",
    "\t\t\t\tr3link  = re.search( r\"reports\\[2\\+1\\] = \\\"(.*?)\\\";\", r.text )\n",
    "\t\t\t\tr4link  = re.search( r\"reports\\[3\\+1\\] = \\\"(.*?)\\\";\", r.text )\n",
    "\t\t\t\tr5link  = re.search( r\"reports\\[4\\+1\\] = \\\"(.*?)\\\";\", r.text )\n",
    "\t\t\t\tr6link  = re.search( r\"reports\\[5\\+1\\] = \\\"(.*?)\\\";\", r.text )\n",
    "\t\t\t\tr7link  = re.search( r\"reports\\[6\\+1\\] = \\\"(.*?)\\\";\", r.text )\n",
    "\t\t\t\tr8link  = re.search( r\"reports\\[7\\+1\\] = \\\"(.*?)\\\";\", r.text )\n",
    "\t\t\t\tr9link  = re.search( r\"reports\\[8\\+1\\] = \\\"(.*?)\\\";\", r.text )\n",
    "\n",
    "\t\t\t\tr1id    = html.find( \"li\", attrs={ 'id': 'r1' } )\n",
    "\t\t\t\tr2id    = html.find( \"li\", attrs={ 'id': 'r2' } )\n",
    "\t\t\t\tr3id    = html.find( \"li\", attrs={ 'id': 'r3' } )\n",
    "\t\t\t\tr4id    = html.find( \"li\", attrs={ 'id': 'r4' } )\n",
    "\t\t\t\tr5id    = html.find( \"li\", attrs={ 'id': 'r5' } )\n",
    "\t\t\t\tr6id    = html.find( \"li\", attrs={ 'id': 'r6' } )\n",
    "\t\t\t\tr7id    = html.find( \"li\", attrs={ 'id': 'r7' } )\n",
    "\t\t\t\tr8id    = html.find( \"li\", attrs={ 'id': 'r8' } )\n",
    "\t\t\t\tr9id    = html.find( \"li\", attrs={ 'id': 'r9' } )\n",
    "\n",
    "\t\t\t\trlinks = (r1link, r2link, r3link, r4link, r5link, r6link, r7link, r8link, r9link)\n",
    "\t\t\t\trids = (r1id, r2id, r3id, r4id, r5id, r6id, r7id, r8id, r9id)\n",
    "\t\t\t\tincome = blance = caflow = pandas.DataFrame()\n",
    "\n",
    "\t\t\t\tfor rid in rids:\n",
    "\t\t\t\t\tif (income.empty) and (rid):\n",
    "\t\t\t\t\t\tif ( (re.search(\"income\", rid.text, re.I)) or (re.search(\"operations\", rid.text, re.I)) ) and ( (not re.search(\"comprehensive\", rid.text, re.I)) or (not re.search(\"parenthetical\", rid.text, re.I)) ):\n",
    "\t\t\t\t\t\t\tincome = self.pprequest( \"https://www.sec.gov\" + rlinks[ rids.index( rid ) ].groups()[0], \"Income\" )\n",
    "\t\t\t\t\tif (blance.empty) and (rid):\n",
    "\t\t\t\t\t\tif ( (re.search(\"balance sheet\", rid.text, re.I)) or (re.search(\"financial position\", rid.text, re.I )) ) and ( (not re.search(\"comprehensive\", rid.text, re.I)) or (not re.search(\"parenthetical\", rid.text, re.I)) ):\n",
    "\t\t\t\t\t\t\tblance = self.pprequest( \"https://www.sec.gov\" + rlinks[ rids.index( rid ) ].groups()[0], \"Balance\" )\n",
    "\t\t\t\t\tif (caflow.empty) and (rid):\n",
    "\t\t\t\t\t\tif ( (re.search(\"CONSOLIDATED STATEMENTS OF CASH FLOWS\", rid.text, re.I)) ) and ( (not re.search(\"comprehensive\", rid.text, re.I)) or (not re.search(\"parenthetical\", rid.text, re.I)) ):\n",
    "\t\t\t\t\t\t\tcaflow = self.pprequest( \"https://www.sec.gov\" + rlinks[ rids.index( rid ) ].groups()[0], \"Cash Flow\" )\n",
    "\n",
    "\t\t\t\tif self.verbose:\n",
    "\t\t\t\t\tself.LOCK.acquire()\n",
    "\t\t\t\t\tprint(\"[*] Received Q10 File. Date: %s\" % _date)\n",
    "\t\t\t\t\tself.LOCK.release()\n",
    "\n",
    "\t\t\t\tself.DATA[ datetime.strptime( _date, \"%Y-%m-%d\" ) ] = ( income, blance, caflow )\n",
    "\t\t\telse:\n",
    "\t\t\t\tif self.verbose:\n",
    "\t\t\t\t\tprint(\"[!] Invalid Response Code Received for link: %s\" % _link)\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\tself.THREADS -= 1\n",
    "\n",
    "\tdef sort(self):\n",
    "\t\t''' This is an object to sort the found files according to their publishing date '''\n",
    "\t\tdateobjs = []\n",
    "\t\tfor ( date, link ) in self.LINKS:\n",
    "\t\t\tdateobjs.append( datetime.strptime( date, \"%Y-%m-%d\" ) )\n",
    "\t\tdateobjs = sorted( dateobjs, reverse=True )[ :self.count ]\n",
    "\t\tfor dateobj in dateobjs:\n",
    "\t\t\tfor ( date, link ) in self.LINKS:\n",
    "\t\t\t\tif date == dateobj.strftime( \"%Y-%m-%d\" ):\n",
    "\t\t\t\t\tself.LOOPER.append( ( date, link ) )\n",
    "\n",
    "\tdef scrape(self):\n",
    "\t\tfor (date, link) in set(self.LOOPER):\n",
    "\t\t\t_t = threading.Thread( target=self.prequest, args=( date, link ) )\n",
    "\t\t\t_t.daemon = True\n",
    "\t\t\t_t.start()\n",
    "\n",
    "\t\t\twhile self.THREADS >= self.max:\n",
    "\t\t\t\ttime.sleep( 1 )\n",
    "\n",
    "\t\t\ttime.sleep( 1 )\n",
    "\n",
    "\t\twhile self.THREADS > 0:\n",
    "\t\t\ttime.sleep( 1 )\n",
    "\t\tif self.verbose:\n",
    "\t\t\tprint(\"[<] Done!\")\n",
    "\t\treturn self.DATA\n",
    "\n",
    "\tdef acquire(self):\n",
    "\t\t''' Function to execute other three functions: search(), sort() and scrape() in sequence '''\n",
    "\t\tself.search()\n",
    "\t\tself.sort()\n",
    "\t\tself.scrape()\n",
    "\n",
    "\t\treturn self.DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[^] Requesting 10Q files from the Server!\n",
      "[*] Received Number of Files: 2 Requested Counter: 100\n",
      "[*] Received Number of Files: 2 Requested Counter: 200\n",
      "[*] Acquired Number of 10Q files: 3\n",
      "[^] Requesting Q10 File! Date: 2018-10-24\n",
      "[^] Requesting Q10 File! Date: 2018-04-26\n",
      "[^] Requesting Q10 File! Date: 2019-01-30\n",
      "[*] Received Q10 File. Date: 2018-10-24\n",
      "[*] Received Q10 File. Date: 2018-04-26\n",
      "[*] Received Q10 File. Date: 2019-01-30\n",
      "[<] Done!\n"
     ]
    }
   ],
   "source": [
    "scraper = SCRAPER( \"MSFT\", 3, _verbose=True, _threads=5 )\n",
    "data = scraper.acquire()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2018, 10, 24, 0, 0),\n",
       " datetime.datetime(2018, 4, 26, 0, 0),\n",
       " datetime.datetime(2016, 10, 20, 0, 0),\n",
       " datetime.datetime(2018, 1, 31, 0, 0),\n",
       " datetime.datetime(2016, 1, 28, 0, 0),\n",
       " datetime.datetime(2017, 1, 26, 0, 0),\n",
       " datetime.datetime(2019, 1, 30, 0, 0),\n",
       " datetime.datetime(2016, 4, 21, 0, 0),\n",
       " datetime.datetime(2017, 10, 26, 0, 0),\n",
       " datetime.datetime(2017, 4, 27, 0, 0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "dateobjs = list(data.keys())\n",
    "dateobjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2019, 1, 30, 0, 0),\n",
       " datetime.datetime(2018, 10, 24, 0, 0),\n",
       " datetime.datetime(2018, 4, 26, 0, 0),\n",
       " datetime.datetime(2018, 1, 31, 0, 0),\n",
       " datetime.datetime(2017, 10, 26, 0, 0),\n",
       " datetime.datetime(2017, 4, 27, 0, 0),\n",
       " datetime.datetime(2017, 1, 26, 0, 0),\n",
       " datetime.datetime(2016, 10, 20, 0, 0),\n",
       " datetime.datetime(2016, 4, 21, 0, 0),\n",
       " datetime.datetime(2016, 1, 28, 0, 0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dateobjs = sorted( dateobjs, reverse=True )\n",
    "dateobjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'2019-01-30'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-56645331b1b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdateobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdateobjs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdatestring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdateobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"%Y-%m-%d\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;34m(\u001b[0m \u001b[0mincome\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcashflow\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mdatestring\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: '2019-01-30'"
     ]
    }
   ],
   "source": [
    "for dateobj in dateobjs:\n",
    "    datestring = dateobj.strftime( \"%Y-%m-%d\" )\n",
    "    ( income, blance, cashflow ) = data[ datestring ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
