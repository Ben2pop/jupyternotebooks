{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import threading\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import pandas\n",
    "import collections\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from datetime import datetime\n",
    "\n",
    "try:\n",
    "    from HTMLParser import HTMLParser  # Python 2\n",
    "except:\n",
    "    from html.parser import HTMLParser # Python 3\n",
    "\n",
    "h = HTMLParser()\n",
    "\n",
    "class SCRAPER:\n",
    "\n",
    "    URL = \"https://www.sec.gov/cgi-bin/browse-edgar?CIK=%s&start=%d&count=100\"\n",
    "    LOCK = threading.Semaphore( value=1 )\n",
    "    THREADS = 0\n",
    "    CCOUNT = 0\n",
    "    ERRORS = 0\n",
    "    FILECOUNT = 0\n",
    "    FILES = True\n",
    "    LINKS = []\n",
    "    LOOPER = []\n",
    "    DATA = {}\n",
    "    HEADERS = {\n",
    "        'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:64.0) Gecko/20100101 Firefox/64.0',\n",
    "    }\n",
    "\n",
    "    def __init__(self, _ticker, _howmany, _threads=5, _verbose=False):\n",
    "        ''' A simple and straightforward Scraper! '''\n",
    "        self.ticker = _ticker\n",
    "        self.count  = _howmany\n",
    "        self.max    = _threads   ## More threads more speed except for the file accumulation process  ##\n",
    "        self.verbose = _verbose  ## Verbose Mode. Print Messages!  ##\n",
    "\n",
    "    def table(self, _html):\n",
    "        links, html = [], soup( _html )\n",
    "        table = html.find( \"table\", attrs={ 'class': 'tableFile2' } )\n",
    "\n",
    "        ## Extracting Data from tables ##\n",
    "        if table:\n",
    "            rows = table.findChildren( \"tr\" )[1:]\n",
    "            for row in rows:\n",
    "                ( file, format, desc, date, number ) = row.findChildren( \"td\" )\n",
    "                if file.text == \"10-Q\" or file.text == \"10-q\" or file.text == \"10q\" or file.text == \"10Q\":\n",
    "                    intdata = format.findChild( \"a\", attrs={ 'id': 'interactiveDataBtn' } )\n",
    "                    if intdata:\n",
    "                        links.append( (date.text, \"https://www.sec.gov%s\" % intdata.get( \"href\" )) )\n",
    "                    else:\n",
    "                        if self.verbose:\n",
    "                            print(\"[!] Received 10Q file without interactive data link. \")\n",
    "            return links\n",
    "        else:\n",
    "            self.FILES = False ## Stop if no table is detected ##\n",
    "\n",
    "    def request(self):\n",
    "        url = self.URL % ( self.ticker, self.CCOUNT )\n",
    "        for n in range( 3 ):                             ##  Retry three times in case an error occurs  ##\n",
    "            try:\n",
    "                r = requests.get( url, headers=self.HEADERS )\n",
    "                if r.status_code == 200:\n",
    "                    self.CCOUNT += 100\n",
    "                    q10links = self.table( r.text )\n",
    "                    self.LINKS += q10links\n",
    "                    if self.verbose:\n",
    "                        print(\"[*] Received Number of Files: %d Requested Counter: %d\" % (len( q10links ), self.CCOUNT))\n",
    "                    self.FILECOUNT += len( q10links )\n",
    "                    if self.FILECOUNT >= self.count:\n",
    "                        self.FILES = False\n",
    "                else:\n",
    "                    raise Exception( \"[~] Invalid Response Code Received : %d\" % r.status_code )\n",
    "                break\n",
    "            except KeyboardInterrupt:\n",
    "                raise KeyboardInterrupt()\n",
    "            except:\n",
    "                if self.verbose:\n",
    "                    print(\"[!] Failed connection to Server. Check Your Connection. Trying Again!\")\n",
    "\n",
    "    def search(self):\n",
    "        if self.verbose:\n",
    "            print(\"[^] Requesting 10Q files from the Server!\")\n",
    "        while self.FILES:\n",
    "            self.request(  )\n",
    "        if self.verbose:\n",
    "            print(\"[*] Acquired Number of 10Q files: %d\" % ( self.count ))\n",
    "\n",
    "    def pprequest( self, _link, _type ):\n",
    "        ''' The main function to extract all financial statements data. It accepts the link to financial document and return it's dataframe as of created by pandas\n",
    "            DataFrame() object. It is highly flexbile and determines whether there are any colspans in the table or not. If there are, they will be extracted and\n",
    "            according deleted when the next colspan is encoundered. whether the argument _link is the link to the financial document and _type is the document type.\n",
    "            _type argument is only for testing purposes. '''\n",
    "        try:\n",
    "            r = requests.get( _link, headers=self.HEADERS )\n",
    "        except:\n",
    "            if self.verbose:\n",
    "                print(\"[!] Error Requesting Financial Statement. Type: %s\" % _type)\n",
    "                return None\n",
    "            if r.status_code == 200:\n",
    "                html = soup( r.text )\n",
    "                table = html.find( \"table\", attrs={ 'class': 'report' } )\n",
    "            if table:\n",
    "                rows, differ, data = table.findChildren( \"tr\" ), 0, collections.OrderedDict()\n",
    "                for row in rows:\n",
    "                    if row.findChild( \"th\" ):\n",
    "                        differ += 1\n",
    "                headerslist = rows[ :differ ]\n",
    "                tabdatalist = rows[ differ: ]\n",
    "                for headers in headerslist:\n",
    "                    headerslist[ headerslist.index( headers ) ] = headers.findChildren( \"th\" )\n",
    "                for tabdata in tabdatalist:\n",
    "                    tabdatalist[ tabdatalist.index( tabdata ) ] = tabdata.findChildren( \"td\" )\n",
    "                for headers in headerslist:\n",
    "                    for header in headers:\n",
    "                        if header.get( \"colspan\" ) and int(header.get( \"colspan\" )) > 1:\n",
    "                            colspan = int( header.get( \"colspan\" ) )\n",
    "                            for col in range( colspan ):\n",
    "                                data[ h.unescape( header.text.encode( \"utf8\" ) ) + \" - \" + h.unescape( headerslist[ headerslist.index( headers ) + 1 ][ col ].text.encode( \"utf8\" )) ] = []\n",
    "                            del headerslist[ headerslist.index( headers ) + 1 ][ :colspan ]\n",
    "                            del colspan\n",
    "                        else: \n",
    "                            data[ h.unescape( header.text.encode( \"utf8\" ) ) ] = []\n",
    "                indexer = data.items()\n",
    "                for ( _key, _value ) in indexer:\n",
    "                    for tabdata in tabdatalist:\n",
    "                        try:\n",
    "                            data[ _key ].append( h.unescape( tabdata[ indexer.index( ( _key, _value ) ) ].text.encode( \"utf8\" ) ) )\n",
    "                        except IndexError:\n",
    "                            data[ _key ].append( \"\" )\n",
    "                return pandas.DataFrame( data, index=range( len( tabdatalist ) ) )\n",
    "            else:\n",
    "                return pandas.DataFrame()\n",
    "\n",
    "    def prequest( self, _date, _link ):\n",
    "        self.THREADS += 1\n",
    "\n",
    "        if self.verbose:\n",
    "            self.LOCK.acquire()\n",
    "            print(\"[^] Requesting Q10 File! Date: %s\" % _date)\n",
    "            self.LOCK.release()\n",
    "\n",
    "        for n in range(2):\n",
    "            r = requests.get( _link )\n",
    "            if r.status_code == 200:\n",
    "                income = \"https://www.sec.gov\" + re.search( r\"reports\\[2\\+1\\] = \\\"(.*?)\\\";\", r.text ).groups()[0]  # Income Document Link #\n",
    "                blance = \"https://www.sec.gov\" + re.search( r\"reports\\[4\\+1\\] = \\\"(.*?)\\\";\", r.text ).groups()[0]  # Balance Document Link #\n",
    "                otflow = \"https://www.sec.gov\" + re.search( r\"reports\\[6\\+1\\] = \\\"(.*?)\\\";\", r.text ).groups()[0]  # Cash Flow Document Link #\n",
    "\n",
    "                income = self.pprequest( income, \"i\" )\n",
    "                blance = self.pprequest( blance, \"b\" )\n",
    "                otflow = self.pprequest( otflow, \"f\" )\n",
    "\n",
    "                if self.verbose:\n",
    "                    self.LOCK.acquire()\n",
    "                    print(\"[*] Received Q10 File. Date: %s\" % _date)\n",
    "                    self.LOCK.release()\n",
    "\n",
    "                self.DATA[ _date ] = ( income, blance, otflow )\n",
    "            else:\n",
    "                if self.verbose:\n",
    "                    print(\"[!] Invalid Response Code Received for link: %s\" % _link)\n",
    "            break\n",
    "\n",
    "        self.THREADS -= 1\n",
    "\n",
    "    def sort(self):\n",
    "        ''' This is an object to sort the found files according to their publishing date '''\n",
    "        dateobjs = []\n",
    "        for ( date, link ) in self.LINKS:\n",
    "            dateobjs.append( datetime.strptime( date.encode( \"utf8\" ), \"%Y-%m-%d\" ) )\n",
    "        dateobjs = sorted( dateobjs, reverse=True )[ :self.count ]\n",
    "        for dateobj in dateobjs:\n",
    "            for ( date, link ) in self.LINKS:\n",
    "                if date == dateobj.strftime( \"%Y-%m-%d\" ):\n",
    "                    self.LOOPER.append( ( date, link ) )\n",
    "\n",
    "    def scrape(self):\n",
    "        for (date, link) in self.LOOPER:\n",
    "            _t = threading.Thread( target=self.prequest, args=( date, link ) )\n",
    "            _t.daemon = True\n",
    "            _t.start()\n",
    "\n",
    "            while self.THREADS >= self.max:\n",
    "                time.sleep( 1 )\n",
    "\n",
    "        while self.THREADS > 0:\n",
    "            time.sleep( 1 )\n",
    "        if self.verbose:\n",
    "            print(\"[<] Done!\")\n",
    "        return self.DATA\n",
    "\n",
    "    def acquire(self):\n",
    "        ''' Function to execute other three functions: search(), sort() and scrape() in sequence '''\n",
    "        self.search()\n",
    "        self.sort()\n",
    "        self.scrape()\n",
    "\n",
    "        return self.DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
